{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn_NN-vs-Keras-Pytorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2021 Qiyang Hu"
      ],
      "metadata": {
        "id": "bv1sDRH-oE38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Licensed under MIT License (the \"License\");\n",
        "# You may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://huqy.github.io/learning_sklearn/LICENSE.md\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "dGKiNHBboJ0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data and code snippets of scikit-learn and keras were adopted from the [benchmark](https://github.com/koaning/benchmarks/blob/main/neural-networks/experiment.py) work.  "
      ],
      "metadata": {
        "id": "JJ5rSTrR4X9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library Imports"
      ],
      "metadata": {
        "id": "yJtjFAKFwkd7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMErvyaYpOd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f235d6f-dd13-4fbb-be19-9d76e18422af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn version:  1.0.2\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import typer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "print(\"Scikit-learn version: \", sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "print(\"Keras version: \", keras.__version__)\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: \", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuVOd8a-5iUq",
        "outputId": "0820d85b-adbe-4a91-a47c-2d4ebddd5a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras version:  2.8.0\n",
            "Tensorflow version:  2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from collections import OrderedDict\n",
        "import torch.optim as optim\n",
        "print(\"PyTorch version: \", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaytCyF6Awio",
        "outputId": "db56f6f4-97dd-4c65-fb99-3446f9417535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version:  1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A small text classification data"
      ],
      "metadata": {
        "id": "NJsxlJgf5Rti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/koaning/tokenwiser/main/data/oos-intent.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtjMugAZrhk_",
        "outputId": "46254678-92ce-4c91-a47a-888f1e446aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-23 18:21:17--  https://raw.githubusercontent.com/koaning/tokenwiser/main/data/oos-intent.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1831657 (1.7M) [text/plain]\n",
            "Saving to: ‘oos-intent.jsonl’\n",
            "\n",
            "oos-intent.jsonl    100%[===================>]   1.75M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-06-23 18:21:17 (37.1 MB/s) - ‘oos-intent.jsonl’ saved [1831657/1831657]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"oos-intent.jsonl\"\n",
        "df = pd.read_json(url, lines=True)"
      ],
      "metadata": {
        "id": "e6oJXFBerw9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1ufn5a09JOx",
        "outputId": "0bb92748-6b73-42f8-df7f-9671b461086b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         text      label\n",
            "0            how would you say fly in italian  translate\n",
            "1           what's the spanish word for pasta  translate\n",
            "2         how would they say butter in zambia  translate\n",
            "3              how do you say fast in spanish  translate\n",
            "4         what's the word for trees in norway  translate\n",
            "...                                       ...        ...\n",
            "23695      what does it mean to have equality        oos\n",
            "23696  what site publishes the most fake news        oos\n",
            "23697          can you tell me some fake news        oos\n",
            "23698                 is cnn really fake news        oos\n",
            "23699                  why is there fake news        oos\n",
            "\n",
            "[23700 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = CountVectorizer().fit_transform(df['text']), df['label']"
      ],
      "metadata": {
        "id": "y4Ph1VZNsfjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "l-R0zGJosq-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train type = \", type(X_train),\"\\t shape = \", X_train.shape)\n",
        "print(\"X_test  type = \", type(X_test),\"\\t shape = \", X_test.shape)\n",
        "print(\"y_train type = \", type(y_train),\"\\t shape = \", y_train.shape)\n",
        "print(\"y_test  type = \", type(y_test),\"\\t shape = \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CODF1w1iehIZ",
        "outputId": "e3e19ddc-785c-4069-bc83-42ac5826f268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train type =  <class 'scipy.sparse.csr.csr_matrix'> \t shape =  (15879, 7233)\n",
            "X_test  type =  <class 'scipy.sparse.csr.csr_matrix'> \t shape =  (7821, 7233)\n",
            "y_train type =  <class 'pandas.core.series.Series'> \t shape =  (15879,)\n",
            "y_test  type =  <class 'pandas.core.series.Series'> \t shape =  (7821,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_enc = CountVectorizer().fit(y_train)\n",
        "y_lab_train = label_enc.transform(y_train)\n",
        "y_lab_test = label_enc.transform(y_test)"
      ],
      "metadata": {
        "id": "SsDjibwb4ssR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_lab_train type = \", type(y_lab_train), \"\\t shape = \", y_lab_train.shape)\n",
        "print(\"y_lab_test  type = \", type(y_lab_test), \"\\t shape = \", y_lab_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHuqV8zKfDqk",
        "outputId": "601df77d-d317-4fa7-ea3b-b27b033845f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_lab_train type =  <class 'scipy.sparse.csr.csr_matrix'> \t shape =  (15879, 151)\n",
            "y_lab_test  type =  <class 'scipy.sparse.csr.csr_matrix'> \t shape =  (7821, 151)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_dense = X_train.todense()\n",
        "y_dense = y_lab_train.todense()\n",
        "print(\"X_dense type is\", type(X_dense), \"\\t shape = \", X_dense.shape)\n",
        "print(\"y_dense type is\", type(y_dense), \"\\t shape = \", y_dense.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5ix6naRgIUZ",
        "outputId": "2649e723-8aa6-46c4-8c5f-3e3886d7d53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_dense type is <class 'numpy.matrix'> \t shape =  (15879, 7233)\n",
            "y_dense type is <class 'numpy.matrix'> \t shape =  (15879, 151)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scikit-Learn Multi-layer Perceptron Implementation"
      ],
      "metadata": {
        "id": "F9hazLJk6HIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_sklearn(X_train, X_test, y_train, y_test):\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "    t0 = time.time()\n",
        "    model = MLPClassifier().fit(X_train, y_train)\n",
        "    t1 = time.time()\n",
        "    pred = model.predict(X_test)\n",
        "    t2 = time.time()\n",
        "    acc = np.mean(pred == y_test)\n",
        "    return {\"train_time\": t1 - t0, \"pred_time\": t2 - t1, \"acc\": float(acc), \"variant\": \"sklearn\"}"
      ],
      "metadata": {
        "id": "3fWHUZTBrW4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_skearly(X_train, X_test, y_train, y_test):\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "    t0 = time.time()\n",
        "    model = MLPClassifier(early_stopping=True).fit(X_train, y_train)\n",
        "    t1 = time.time()\n",
        "    pred = model.predict(X_test)\n",
        "    t2 = time.time()\n",
        "    acc = np.mean(pred == y_test)\n",
        "    return {\"train_time\": t1 - t0, \"pred_time\": t2 - t1, \"acc\": float(acc), \"variant\": \"skearly\"}"
      ],
      "metadata": {
        "id": "7wBqgba_rdKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras Implementation"
      ],
      "metadata": {
        "id": "-wpp7plp6Q5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_keras(X_train, X_test, y_train, y_test):\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense\n",
        "    from keras.optimizer_v2.adam import Adam\n",
        "\n",
        "    label_enc = CountVectorizer().fit(y_train)\n",
        "    y_lab_train = label_enc.transform(y_train)\n",
        "    y_lab_test = label_enc.transform(y_test)\n",
        "\n",
        "    clf = Sequential()\n",
        "    clf.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))\n",
        "    clf.add(Dense(y_lab_train.shape[1], activation='sigmoid',))\n",
        "    clf.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "    \n",
        "    t0 = time.time()\n",
        "    X_dense, y_dense = X_train.todense(), y_lab_train.todense()\n",
        "    clf.fit(x=X_dense, y=y_dense, epochs=10)\n",
        "    t1 = time.time()\n",
        "    pred = np.argmax(clf.predict(X_test.todense()), axis=1)\n",
        "    t2 = time.time()\n",
        "    true_vals = np.asarray(np.argmax(y_lab_test.todense(), axis=1)).flatten()\n",
        "    acc = np.mean(pred == true_vals)\n",
        "    return {\"train_time\": t1 - t0, \"pred_time\": t2 - t1, \"acc\": float(acc), \"variant\": \"keras\"}"
      ],
      "metadata": {
        "id": "d6XUvOMarfJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Implementation"
      ],
      "metadata": {
        "id": "lkSEzEGz_CFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_torch(X_train, X_test, y_train, y_test):\n",
        "    label_enc = CountVectorizer().fit(y_train)\n",
        "    y_lab_train = label_enc.transform(y_train)\n",
        "    y_lab_test = label_enc.transform(y_test)\n",
        "    X_dense = X_train.todense()\n",
        "    y_dense = y_lab_train.todense()\n",
        "\n",
        "    dl_train = DataLoader(TensorDataset(torch.tensor(X_dense).float(), torch.tensor(y_dense).float()), shuffle=True, batch_size=256)\n",
        "\n",
        "    seq_model = nn.Sequential(OrderedDict([\n",
        "        ('hidden_linear', nn.Linear(X_train.shape[1], 100)),\n",
        "        ('hidden_activation', nn.ReLU()),\n",
        "        ('output_linear', nn.Linear(100, y_lab_train.shape[1]))\n",
        "    ]))\n",
        "\n",
        "    n_epochs = 10\n",
        "    optimizer = optim.Adam(seq_model.parameters(), lr=0.02)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    metric_name = \"accuracy\"\n",
        "\n",
        "    def metric_func(y_pred, y_test):\n",
        "        pred = np.argmax(y_pred.data, axis=1).numpy()\n",
        "        true_vals = np.asarray(np.argmax(y_test, axis=1)).flatten()\n",
        "        return np.mean(pred == true_vals)\n",
        "\n",
        "    t0 = time.time()\n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        seq_model.train()\n",
        "        loss_sum = 0.0\n",
        "        metric_sum = 0.0\n",
        "        step = 1\n",
        "        t00 = time.time()\n",
        "        for step, (features,labels) in enumerate(dl_train,1):\n",
        "            optimizer.zero_grad()\n",
        "            preds = seq_model(features)\n",
        "            loss = loss_fn(preds, labels)\n",
        "            metric = metric_func(preds, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            metric_sum += metric.item()\n",
        "            loss_sum += loss.item()\n",
        "        t01 = time.time()\n",
        "        info = (epoch, t01-t00, loss_sum/step, metric_sum/step)\n",
        "        print((\"Epoch = %d/\" +  str(n_epochs) + \", time: %.3f s, loss = %.3f,\"+ metric_name + \" = %.3f\") %info)\n",
        "    t1 = time.time()\n",
        "    y_pred = seq_model(torch.tensor(X_test.todense()).float()).data\n",
        "    pred = np.argmax(y_pred, axis=1)\n",
        "    t2 = time.time()\n",
        "    true_vals = np.asarray(np.argmax(y_lab_test.todense(), axis=1)).flatten()\n",
        "    acc = np.mean(pred.numpy() == true_vals)\n",
        "    return {\"train_time\": t1 - t0, \"pred_time\": t2 - t1, \"acc\": float(acc), \"variant\": \"pytorch\"}"
      ],
      "metadata": {
        "id": "t4T6MDVCDwDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Tests"
      ],
      "metadata": {
        "id": "okjpyylE_qgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_sklearn(X_train, X_test, y_train, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76FRm57assFu",
        "outputId": "2f3aa22f-1712-4558-ddf8-8cff75668d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_time': 268.02961015701294, 'pred_time': 0.08180093765258789, 'acc': 0.9138217619230278, 'variant': 'sklearn'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_skearly(X_train, X_test, y_train, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9iZHAvlt6Xz",
        "outputId": "d4bfe910-431d-473a-8b4e-ae282142afb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_time': 86.54920196533203, 'pred_time': 0.09106016159057617, 'acc': 0.9197033627413375, 'variant': 'skearly'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_keras(X_train, X_test, y_train, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaiu71GAs0lO",
        "outputId": "d859a1ff-8749-46af-f754-f5402e14ef8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "497/497 [==============================] - 13s 21ms/step - loss: 3.2659 - accuracy: 0.3803\n",
            "Epoch 2/10\n",
            "497/497 [==============================] - 10s 21ms/step - loss: 0.7508 - accuracy: 0.8849\n",
            "Epoch 3/10\n",
            "497/497 [==============================] - 11s 23ms/step - loss: 0.3335 - accuracy: 0.9432\n",
            "Epoch 4/10\n",
            "497/497 [==============================] - 9s 19ms/step - loss: 0.1959 - accuracy: 0.9676\n",
            "Epoch 5/10\n",
            "497/497 [==============================] - 9s 19ms/step - loss: 0.1275 - accuracy: 0.9818\n",
            "Epoch 6/10\n",
            "497/497 [==============================] - 8s 16ms/step - loss: 0.0879 - accuracy: 0.9884\n",
            "Epoch 7/10\n",
            "497/497 [==============================] - 6s 12ms/step - loss: 0.0631 - accuracy: 0.9922\n",
            "Epoch 8/10\n",
            "497/497 [==============================] - 6s 12ms/step - loss: 0.0465 - accuracy: 0.9948\n",
            "Epoch 9/10\n",
            "497/497 [==============================] - 6s 12ms/step - loss: 0.0354 - accuracy: 0.9962\n",
            "Epoch 10/10\n",
            "497/497 [==============================] - 5s 11ms/step - loss: 0.0272 - accuracy: 0.9970\n",
            "{'train_time': 86.53141403198242, 'pred_time': 1.4413535594940186, 'acc': 0.9218769978263649, 'variant': 'keras'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_torch(X_train, X_test, y_train, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ65LK6GECvT",
        "outputId": "d1f3b3b6-8460-418f-ec17-f326eee20c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch = 1/10, time: 2.547 s, loss = 1.477,accuracy = 0.690\n",
            "Epoch = 2/10, time: 2.337 s, loss = 0.116,accuracy = 0.970\n",
            "Epoch = 3/10, time: 2.398 s, loss = 0.045,accuracy = 0.988\n",
            "Epoch = 4/10, time: 2.264 s, loss = 0.021,accuracy = 0.995\n",
            "Epoch = 5/10, time: 2.212 s, loss = 0.015,accuracy = 0.997\n",
            "Epoch = 6/10, time: 2.260 s, loss = 0.011,accuracy = 0.998\n",
            "Epoch = 7/10, time: 2.482 s, loss = 0.010,accuracy = 0.998\n",
            "Epoch = 8/10, time: 3.238 s, loss = 0.012,accuracy = 0.997\n",
            "Epoch = 9/10, time: 2.372 s, loss = 0.009,accuracy = 0.998\n",
            "Epoch = 10/10, time: 2.089 s, loss = 0.006,accuracy = 0.999\n",
            "{'train_time': 24.208744049072266, 'pred_time': 0.595595121383667, 'acc': 0.9144610663598005, 'variant': 'pytorch'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFjzh6Jru8Nk",
        "outputId": "94a1386f-76de-4da4-c7bd-97b44d617b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31284 sha256=9c9b322dc64fc3f06c354ad6b9804d7e7321aac302c5cf3e047453393dad231b\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/2b/fb/326e30d638c538e69a5eb0aa47f4223d979f502bbdb403950f\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.60.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext memory_profiler"
      ],
      "metadata": {
        "id": "EMzkUIdYvRiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peak memory refers to the peak memory usage of your system (including memory usage of other processes) during the program runtime.\n",
        "\n",
        "Increment is the increment in memory usage relative to the memory usage just before the program is run (i.e. increment = peak memory - starting memory)."
      ],
      "metadata": {
        "id": "WqNpJN745Wz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%memit run_sklearn(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5qfINxnva6b",
        "outputId": "ee962b66-6996-41fa-83d1-bb0f5737fcca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 5174.36 MiB, increment: 0.02 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%memit run_skearly(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBXDg7S1vts8",
        "outputId": "e08564c1-5e36-4e35-c6fe-c4f19fda143c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 4957.23 MiB, increment: 3.88 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%memit run_keras(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZt8WP-NvWVM",
        "outputId": "d9979232-f0a4-461f-b3b3-329b82ee49d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "497/497 [==============================] - 8s 16ms/step - loss: 3.2699 - accuracy: 0.3876\n",
            "Epoch 2/10\n",
            "497/497 [==============================] - 7s 14ms/step - loss: 0.7381 - accuracy: 0.8892\n",
            "Epoch 3/10\n",
            "497/497 [==============================] - 7s 14ms/step - loss: 0.3270 - accuracy: 0.9444\n",
            "Epoch 4/10\n",
            "497/497 [==============================] - 7s 13ms/step - loss: 0.1920 - accuracy: 0.9691\n",
            "Epoch 5/10\n",
            "497/497 [==============================] - 7s 15ms/step - loss: 0.1248 - accuracy: 0.9818\n",
            "Epoch 6/10\n",
            "497/497 [==============================] - 7s 15ms/step - loss: 0.0863 - accuracy: 0.9885\n",
            "Epoch 7/10\n",
            "497/497 [==============================] - 7s 14ms/step - loss: 0.0623 - accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "497/497 [==============================] - 7s 14ms/step - loss: 0.0460 - accuracy: 0.9952\n",
            "Epoch 9/10\n",
            "497/497 [==============================] - 6s 13ms/step - loss: 0.0346 - accuracy: 0.9963\n",
            "Epoch 10/10\n",
            "497/497 [==============================] - 7s 14ms/step - loss: 0.0271 - accuracy: 0.9971\n",
            "peak memory: 4754.48 MiB, increment: 825.00 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%memit run_torch(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXtyde7zE3l6",
        "outputId": "2f0ca046-c07a-4031-c4a3-7571a671059c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch = 1/10, time: 2.113 s, loss = 1.485,accuracy = 0.680\n",
            "Epoch = 2/10, time: 2.275 s, loss = 0.127,accuracy = 0.965\n",
            "Epoch = 3/10, time: 2.239 s, loss = 0.045,accuracy = 0.990\n",
            "Epoch = 4/10, time: 2.295 s, loss = 0.020,accuracy = 0.996\n",
            "Epoch = 5/10, time: 2.224 s, loss = 0.014,accuracy = 0.997\n",
            "Epoch = 6/10, time: 2.175 s, loss = 0.010,accuracy = 0.998\n",
            "Epoch = 7/10, time: 2.011 s, loss = 0.010,accuracy = 0.998\n",
            "Epoch = 8/10, time: 2.016 s, loss = 0.009,accuracy = 0.998\n",
            "Epoch = 9/10, time: 2.144 s, loss = 0.009,accuracy = 0.998\n",
            "Epoch = 10/10, time: 2.015 s, loss = 0.008,accuracy = 0.998\n",
            "peak memory: 5174.32 MiB, increment: 419.85 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Summary"
      ],
      "metadata": {
        "id": "DI97twhQen4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| Implementation | Train Time | Predict Time | Test Accuracy | Memory Usage |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| Scikit-learn | 268.03 | 0.082 | 0.914 | 0.02 MB |\n",
        "| Scikit-learn Early Stopping| 85.55 | 0.091 | 0.920 | 3.88 MB |\n",
        "| Keras| 86.53 | 1.441 | 0.922 | 825.00 MB |\n",
        "| PyTorch| 24.21 | 0.596 | 0.914 | 419.85 MB |"
      ],
      "metadata": {
        "id": "tYckpJFbbPey"
      }
    }
  ]
}